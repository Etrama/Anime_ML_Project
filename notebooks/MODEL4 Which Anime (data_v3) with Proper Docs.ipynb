{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow\n",
    "#!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import mlcrate as mlc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the experiment tracking in MODEL3 was all over the place, we need a better system to track and evaluate our experiments. That's what this notebook is for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracker:\n",
    "- [X] From MODEL3 we already know that resnet50 is doing better than resnet34. Let's use that information and experiment with other paramets. After all other experiments are done, we could try the resnet 34 vs resnet 50 thing again. But, for now, consider it shelved.\n",
    "\n",
    "### So, with resnet-50 as our model:\n",
    "- [ ] Try batch size 16, 32, 64, 128. Batch size influences what is the size of the batch loaded onto the GPUs in one iteration. See if this changes execution speed at all. Size set as 300.\n",
    "- [ ] Try image sizes 112, 168, 224, 280, 336, 392. These are all square sizes.\n",
    "- [ ] Try standard sizes. Try standard non-square sizes as well.\n",
    "- [ ] Try different available image color maps.\n",
    "- [ ] Try using different Transforms.\n",
    "- [ ] Are Data Augmentations and Transforms entirely different things? From the names, it does seem like it.\n",
    "- [ ] If yes to the above, try data augmentation too.\n",
    "- [ ] Try Normalization.\n",
    "- [ ] Figure out why there are only 97 classes and not 100. Find out which ones are missing.\n",
    "- [ ] Try all the models mentioned here: https://docs.fast.ai/vision.models.html. Train and tune them separately, apart from resnet34 and resnet50.\n",
    "- [ ] Train a n/w with the best parameters for all of these.\n",
    "- [ ] Finetune and unfreeze post above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_trials():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug_trials():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_trials():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_size_trials(batch_size):\n",
    "    data = ImageDataBunch.from_folder(\"./data_v3/Anime_Recogntn_Images/\" , size = 300, valid_pct= 0.15, seed = 42, bs = batch_size)\n",
    "    path = Path('~./Anime_Project/data_v3/Anime_Recogntn_Images')\n",
    "    \n",
    "    classes = data.classes\n",
    "    for c in classes:\n",
    "        #print(c)\n",
    "        verify_images(path/c, delete=True, size = 500)\n",
    "    \n",
    "    learn = cnn_learner(data, models.resnet50, metrics = error_rate)\n",
    "    \n",
    "    print(\"Train Cycle 1\")\n",
    "    learn.fit_one_cycle(8, max_lr=slice(1e-3,1e-2))\n",
    "    learn.recorder.plot_losses()\n",
    "    \n",
    "    \n",
    "    print(\"Train Cycle 2\")\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(15, max_lr=slice(1e-3,1e-2))\n",
    "    print(learn.recorder.plot_losses())\n",
    "    \n",
    "    print(\"Train Cycle 3\")\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(15, max_lr=slice(1e-4,1e-3))\n",
    "    print(learn.recorder.plot_losses())\n",
    "    \n",
    "    learn.save('stage-1-50-data_v3_batch_size_trials_' + str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cycle 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [6/8 14:55<04:58]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.446380</td>\n",
       "      <td>3.278411</td>\n",
       "      <td>0.882266</td>\n",
       "      <td>02:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.150721</td>\n",
       "      <td>3.071841</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.092966</td>\n",
       "      <td>3.803028</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>02:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.937742</td>\n",
       "      <td>2.750936</td>\n",
       "      <td>0.866814</td>\n",
       "      <td>02:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.778161</td>\n",
       "      <td>2.682721</td>\n",
       "      <td>0.872701</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.633311</td>\n",
       "      <td>2.570116</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='220' class='' max='481', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      45.74% [220/481 00:50<01:00 2.4955]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = mlc.time.Timer()\n",
    "batch_size_trials(16)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "batch_size_trials(32)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "batch_size_trials(64)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "batch_size_trials(128)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_size_trials([size_ip]):\n",
    "    data = ImageDataBunch.from_folder(\"./data_v3/Anime_Recogntn_Images/\" , size = size_ip, valid_pct= 0.15, seed = 42, bs = 64)\n",
    "    path = Path('~./Anime_Project/data_v3/Anime_Recogntn_Images')\n",
    "    \n",
    "    classes = data.classes\n",
    "    for c in classes:\n",
    "        #print(c)\n",
    "        verify_images(path/c, delete=True, size = 500)\n",
    "    \n",
    "    learn = cnn_learner(data, models.resnet50, metrics = error_rate)\n",
    "    \n",
    "    learn.fit_one_cycle(8, max_lr=slice(1e-3,1e-2))\n",
    "    print(\"Train Cycle 1\")\n",
    "    print(learn.recorder.plot_losses())\n",
    "    \n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(15, max_lr=slice(1e-3,1e-2))\n",
    "    print(\"Train Cycle 2\")\n",
    "    print(learn.recorder.plot_losses())\n",
    "    \n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(15, max_lr=slice(1e-4,1e-3))\n",
    "    print(\"Train Cycle 3\")\n",
    "    print(learn.recorder.plot_losses())\n",
    "    \n",
    "    learn.save('stage-1-50-data_v3_batch_size_trials_' + str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(112)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(168)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(224)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(280)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(336)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(392)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(320,50)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(300,100)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(240,400)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mlc.time.Timer()\n",
    "image_size_trials(300,250)\n",
    "print(\"Time taken: {}\".format(time.since(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
